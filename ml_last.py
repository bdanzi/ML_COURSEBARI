# -*- coding: utf-8 -*-
"""ML_COURSEBARI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1em4lHGCvzau6VcGXR63nYVqHQm_hQAoa
"""

# KFJ14MAY2022; practice Keras DNN
# BRUFRA16MAY2022; practice Keras DNN, scikit-learn BDT
import numpy as np
from numpy import loadtxt
from matplotlib import pyplot as plt
import tensorflow
from keras.models import  Sequential
#from keras.models import Sequential  <<== errors
from keras.layers import Dense, Dropout
#from keras.layers import Dense   <<== gave errors
from sklearn.metrics import roc_curve, auc, mean_squared_error  ## To show results
from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

EPOCHS=500
LOQUACIOUS=0
model_file = 'ANN_model.h5'
##Call functions implementation to monitor the chosen metrics
checkpoint = ModelCheckpoint(filepath = model_file,
                                             monitor = 'val_loss',
                                             mode='min',
                                             save_best_only = True)

#Stop training when a monitored metric has stopped improving
early_stop = EarlyStopping(monitor = 'val_loss',
                                           mode='min',# quantity that has to be monitored(to be minimized in this case)
                              patience = 50, # Number of epochs with no improvement after which training will be stopped.
                              min_delta = 1e-7,
                              restore_best_weights = True) # update the model with the best-seen weights

#Reduce learning rate when a metric has stopped improving
reduce_LR = ReduceLROnPlateau( monitor = 'val_loss',
                                              mode='min',# quantity that has to be monitored
                                              min_delta=1e-7,
                                              factor = 0.1, # factor by which LR has to be reduced...
                                              patience = 10, #...after waiting this number of epochs with no improvements 
                                              #on monitored quantity
                                              min_lr= 0.00001 ) 


callback_list = [reduce_LR, early_stop, checkpoint]

dat = loadtxt('NormDat_train.txt', delimiter=' ')
y = dat[:,0]
x = dat[:, 1:24]

## Load test data into arrays.
test = loadtxt('NormDat_test.txt', delimiter=' ')
ytst = test[:,0]
xtst = test[:, 1:24]

## Set up classifier structure
cl1 = Sequential()  ## type of classifier
cl1.add(Dense( 100,  activation='selu'))    ## First hidden layer # of nodes; densely connected
cl1.add(Dropout(rate=0.1))
cl1.add(Dense(  50,  activation='selu'))    ## 2nd layer
cl1.add(Dropout(rate=0.1))
cl1.add(Dense(   40,  activation='selu'))
cl1.add(Dense(   1,  activation='sigmoid')) ## Output layer uses sigmoid for classification


## Set up classifier structure
cl = Sequential()  ## type of classifier
cl.add(Dense( 100,  activation='selu'))    ## First hidden layer # of nodes; densely connected
cl.add(Dropout(rate=0.1))
cl.add(Dense(  50,  activation='selu'))    ## 2nd layer
cl.add(Dropout(rate=0.1))
cl.add(Dense(   40,  activation='selu'))
cl.add(Dense(   1,  activation='sigmoid')) ## Output layer uses sigmoid for classification

## Try out different loss functions, some better, some worse.
#cl.compile( loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'] )  ## <<==good

cl.compile( loss='MeanSquaredError', optimizer='adam', metrics=['accuracy'] )   ## <<== good
cl1.compile( loss='MeanSquaredError', optimizer='adam', metrics=['accuracy'] )   ## <<== good

#cl.compile( loss='Hinge', optimizer='adam', metrics=['accuracy'] )  ##<<== not so good


Chunk=50         # how many events per chunk
NumChuncks=50  #     .... times this determines number of training events used.
Scores_train=[]
mse_train=[]
mse_test=[]
Scores_test=[]
Scores_trainsize=[]
for iter in range(1, NumChuncks):
    TrainSize= Chunk * iter
    y_train = np.empty((TrainSize))  ## Reserve memory for trainng data...
    y_train = y[0:TrainSize]
    X_train = np.zeros((TrainSize, 23))
    for row in range(TrainSize):
        X_train[row] = x[row]
    cl.fit(X_train,y_train,epochs=EPOCHS, batch_size=256, verbose=LOQUACIOUS, validation_split=0.1) # Fitting procedure which determines the MLP weights by using a fraction TrainSize of training data
    y_score_test = cl.predict(xtst)
    y_score_train = cl.predict(X_train)
    #TrainScore = cl.score(X_train, y_train)
    #TestScore  = cl.score( xtst, ytst)
    Mse_train = mean_squared_error(y_train,y_score_train)
    Mse_test = mean_squared_error(ytst,y_score_test)
    Scores_trainsize.append(iter*1.0*Chunk)
    #Scores_train.append(TrainScore)
    #Scores_test.append(TestScore)
    mse_train.append(Mse_train)
    mse_test.append(Mse_test)
    #print("ITER: ", iter, "TrainScore: ", "%.5f" % TrainScore, "TestScore: ", "%.5f" %  TestScore  )

if EPOCHS < 100:  LOQUACIOUS=1
mlpfitted = cl.fit(x,y,epochs=EPOCHS, batch_size=128, verbose=LOQUACIOUS, validation_split=0.1, callbacks = callback_list)
cl.evaluate(x,y)
print("Training Done")
    
# plot the loss fuction vs epoch during the training phase
# the plot of the loss function on the validation set is also computed and plotted
plt.rcParams['figure.figsize'] = (13,6)
plt.plot(mlpfitted.history['loss'], label='loss train',color='green')
plt.plot(mlpfitted.history['val_loss'], label='loss validation',color='magenta')
plt.title("Loss", fontsize=12,fontweight='bold', color='r')
plt.legend(loc="upper right")
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid("True")
plt.savefig("loss_vs_epocs.png", dpi=300)
plt.show()
plt.close()

#######################################################################################################
## Plotting the MLP score vs Trainsize, increasing this number in steps of Chunk number##
#######################################################################################################
# =============================================================================
# plt.plot(Scores_trainsize,Scores_train,"o-",label = "Training data set")
# plt.plot(Scores_trainsize,Scores_test,"o-",label = "Test data set")
# ## naming the x axis
# plt.xlabel('Number of training samples')
# ## naming the y axis
# plt.ylabel('MLP score')
# ## giving a title to my graph
# plt.title('Training and test score on Training and Test samples')
# ## show a legend on the plot
# plt.legend(['Training data set','Validation data set'])
# plt.savefig('numbertrainingsamples_MLP_score.png', dpi=300, bbox_inches='tight')
# plt.show()
# plt.close()
# =============================================================================

#bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm="SAMME", n_estimators=700)
bdt = GradientBoostingClassifier()
rf = RandomForestClassifier( n_estimators=300,criterion='gini',
                           verbose=0 , min_samples_split=200, 
                           max_depth= 5,min_samples_leaf=500, 
                           max_features=4, bootstrap=False,random_state=7 )
rf.fit(x,y)

bdt.fit(x,y)
print("Start training")
if EPOCHS < 1000:  LOQUACIOUS=1
cl1.fit(x,y,epochs=EPOCHS, batch_size=128, verbose=LOQUACIOUS, validation_split=0.1)#, callbacks = callback_list)
cl1.evaluate(x,y)
print("Training Done")
OOB_train = np.zeros((len(x), 2))  ## Set up to collect Out-Of-Bag results
OOBResults_train = cl1.predict(x)
for i in range(len(y)):
    OOB_train[i,0] = y[i]
    OOB_train[i,1] = OOBResults_train[i]

np.savetxt('OOB_train.txt', OOB_train , fmt="%d  %.7f")  ##<<== test results are saved here!

OOB_test = np.zeros((len(ytst), 2))  ## Set up to collect Out-Of-Bag results

OOBResults_test = cl1.predict(xtst)  ## Get predictions from NN on test data.

for i in range(len(ytst)):      ## Put results into array for plotting, writing,...
    OOB_test[i,0] = ytst[i]
    OOB_test[i,1] = OOBResults_test[i]
## Preview
for i in range(20):
    print(OOBResults_test[i], ytst[i]) 
print("Testing predictions available: \n", cl1.evaluate(xtst,ytst) )
np.savetxt('OOB_test.txt', OOB_test , fmt="%d  %.7f")  ##<<== test results are saved here!

#############################################################################################################################
## Plotting the Mean square error loss function vs size of training sample, increasing this number in steps of Chunk number##
#############################################################################################################################
plt.clf() # clean the figure
plt.plot(Scores_trainsize,mse_train,"o-",label = "Training data set")
plt.plot(Scores_trainsize,mse_test,"o-",label = "Test data set")
## naming the x axis
plt.xlabel('Number of training samples')
## naming the y axis
plt.ylabel('Mean square error')
## giving a title to my graph
plt.title('Training and test loss function on Training and Test samples')
## show a legend on the plot
plt.legend(['Training data set','Validation data set'])
plt.savefig('numbertrainingsamples_loss_mse.png', dpi=300, bbox_inches='tight')
plt.show()
plt.close()

#Plotting ROC curve
fpr_test = dict()
tpr_test = dict()
roc_auc_test = dict()
fpr_train = dict()
tpr_train = dict()
roc_auc_train = dict()

fpr_test_bdt = dict()
tpr_test_bdt = dict()
roc_auc_test_bdt = dict()
fpr_train_bdt = dict()
tpr_train_bdt = dict()
roc_auc_train_bdt = dict()

fpr_test_rf = dict()
tpr_test_rf = dict()
roc_auc_test_rf = dict()
fpr_train_rf = dict()
tpr_train_rf = dict()
roc_auc_train_rf = dict()
lw=2

fpr_test, tpr_test, _ = roc_curve(ytst, OOBResults_test)
roc_auc_test = auc(fpr_test, tpr_test)
fpr_train, tpr_train, _ = roc_curve(y, OOBResults_train)
roc_auc_train = auc(fpr_train, tpr_train)

y_score_test_bdt = bdt.predict_proba(xtst) # MLP prediction on test data
y_score_training_bdt = bdt.predict_proba(x)# MLP prediction on training data

y_score_test_rf = rf.predict_proba(xtst) # MLP prediction on test data
y_score_training_rf = rf.predict_proba(x)# MLP prediction on training data

fpr_test_bdt, tpr_test_bdt, _ = roc_curve(ytst, y_score_test_bdt[:,1])
roc_auc_test_bdt = auc(fpr_test_bdt, tpr_test_bdt)
fpr_train_bdt, tpr_train_bdt, _ = roc_curve(y, y_score_training_bdt[:,1])
roc_auc_train_bdt = auc(fpr_train_bdt, tpr_train_bdt)

fpr_test_rf, tpr_test_rf, _ = roc_curve(ytst, y_score_test_rf[:,1])
roc_auc_test_rf = auc(fpr_test_rf, tpr_test_rf)
fpr_train_rf, tpr_train_rf, _ = roc_curve(y, y_score_training_rf[:,1])
roc_auc_train_rf = auc(fpr_train_rf, tpr_train_rf)

score_mp_sig_test = []
score_mp_sig_train = []
score_mp_bkg_train = []
score_mp_bkg_test = []
score_bdt_sig_test = []
score_bdt_sig_train = []
score_bdt_bkg_train = []
score_bdt_bkg_test = []
score_rf_sig_test = []
score_rf_sig_train = []
score_rf_bkg_train = []
score_rf_bkg_test = []
for i in range(len(ytst)): #xtst
  if ytst[i] == 1:
    score_mp_sig_test.append(OOBResults_test[i])
    score_bdt_sig_test.append(y_score_test_bdt[i,1])
    score_rf_sig_test.append(y_score_test_rf[i,1])
  if ytst[i] == 0:
    score_mp_bkg_test.append(OOBResults_test[i])
    score_bdt_bkg_test.append(y_score_test_bdt[i,1])
    score_rf_bkg_test.append(y_score_test_rf[i,1])
for i in range(len(y)): #xtst
  if y[i] == 1:
    score_mp_sig_train.append(OOBResults_train[i])
    score_bdt_sig_train.append(y_score_training_bdt[i,1])
    score_rf_sig_train.append(y_score_training_rf[i,1])
  if y[i] == 0:
    score_mp_bkg_train.append(OOBResults_train[i])
    score_bdt_bkg_train.append(y_score_training_bdt[i,1])
    score_rf_bkg_train.append(y_score_training_rf[i,1])

print(score_bdt_bkg_train)
print(score_bdt_sig_train)
print(score_bdt_bkg_test)
print(score_bdt_sig_test)
print(len(score_bdt_bkg_test))
print(len(score_bdt_sig_test))
print(len(score_bdt_bkg_train))
print(len(score_bdt_sig_train))
print(score_mp_bkg_train)
print(score_mp_sig_train)
print(score_mp_bkg_test)
print(score_mp_sig_test)
print(len(score_mp_bkg_test))
print(len(score_mp_sig_test))
print(len(score_mp_bkg_train))
print(len(score_mp_sig_train))

plt.figure()
#plt.plot(score_mp_sig_test,score_bdt_sig_test,"o",color="darkblue",label="Signal Test events")
plt.plot(score_mp_sig_train,score_bdt_sig_train,"o",color="darkorange",lw=lw,label="Signal Train events")
#plt.plot(score_mp_bkg_test,score_bdt_bkg_test,"o",color="darkgreen",label="Bkg Test events")
plt.plot(score_mp_bkg_train,score_bdt_bkg_train,"o",color="purple",lw=lw,label="Bkg Train events")
plt.plot([0, 1], [0, 1], color="navy", lw=lw, linestyle="--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("MLP score")
plt.ylabel("BDT score")
plt.legend(loc="lower right")
plt.title("Machine Learning Algorithm scores")
plt.savefig("comparison_scores_mlp_bdt.png", dpi=300)
plt.show()

plt.figure()
#plt.plot(score_mp_sig_test,score_bdt_sig_test,"o",color="darkblue",label="Signal Test events")
plt.plot(score_mp_sig_train,score_rf_sig_train,"o",color="darkorange",lw=lw,label="Signal Train events")
#plt.plot(score_mp_bkg_test,score_bdt_bkg_test,"o",color="darkgreen",label="Bkg Test events")
plt.plot(score_mp_bkg_train,score_rf_bkg_train,"o",color="purple",lw=lw,label="Bkg Train events")
plt.plot([0, 1], [0, 1], color="navy", lw=lw, linestyle="--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("MLP score")
plt.ylabel("RF score")
plt.legend(loc="lower right")
plt.title("Machine Learning Algorithm scores")
plt.savefig("comparison_scores_mlp_rf.png", dpi=300)
plt.show()

# =============================================================================
# plt.figure()
# plt.hist(x=score_mp_bkg_test,bins= 3,facecolor='g', range=[0,1],alpha=0.75,label="Bkg Test events",histtype='bar')
# #plt.hist(score_mp_bkg_train,bins= [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],label="Bkg Train events")
# #plt.hist(score_mp_sig_test,bins= [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],label="Signal Test events")
# #plt.hist(score_mp_sig_train,bins= [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],label="Bkg Test events")
# plt.legend(loc="lower right")
# plt.style.use('ggplot')
# plt.xlabel("MLP score")
# plt.savefig("comparison_scores_mlp_histo.png", dpi=300)
# plt.show()
# 
# =============================================================================
plt.figure()
plt.plot(fpr_test_bdt,tpr_test_bdt,color="darkblue",lw=lw,label="BDT Test ROC curve (area = %0.2f)" % roc_auc_test_bdt)
plt.plot(fpr_train_bdt,tpr_train_bdt,color="green",lw=lw,label="BDT Train ROC curve (area = %0.2f)" % roc_auc_train_bdt)
plt.plot(fpr_test_rf,tpr_test_rf,color="darkblue",lw=lw,label="RF Test ROC curve (area = %0.2f)" % roc_auc_test_rf)
plt.plot(fpr_train_rf,tpr_train_rf,color="green",lw=lw,label="RF Train ROC curve (area = %0.2f)" % roc_auc_train_rf)
plt.plot(fpr_test,tpr_test,color="darkorange",lw=lw,label="DNN Test ROC curve (area = %0.2f)" % roc_auc_test)
plt.plot(fpr_train,tpr_train,color="purple",lw=lw,label="DNN Train ROC curve (area = %0.2f)" % roc_auc_train)
plt.plot([0, 1], [0, 1], color="navy", lw=lw, linestyle="--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.grid("True")
plt.title("Receiver operating characteristic example")
plt.legend(loc="lower right")
plt.savefig("ROC_curve.png", dpi=300)
plt.show()